{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import SGD\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.initializers import VarianceScaling,RandomNormal\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DEC import DEC , plot_animated_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "folder_name = 'results_with_uniform_glorot' # for saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_r = x_train.reshape(60000,28*28)\n",
    "x_test_r = x_test.reshape(10000,28*28)\n",
    "x_train_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init = VarianceScaling(scale=1. / 3, mode='fan_in', distribution='uniform')  \n",
    "#init = RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "init = 'glorot_uniform'\n",
    "dec = DEC(dims=[784, 700, 500, 200, 3], n_clusters=10, init=init)\n",
    "Encoded = dec.encoder.predict(x_train_r)\n",
    "fig = pyplot.figure(figsize=(10,10))\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(Encoded[:,0], Encoded[:,1], Encoded[:,2], s=0.05, c = 'b', marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "dec.pretrain(x=x_train_r,\n",
    "               y=None,\n",
    "               validation_data=(x_test_r, x_test_r),\n",
    "               #validation_split=0.1,\n",
    "               optimizer='adam',\n",
    "               epochs=700,\n",
    "               batch_size=2048,\n",
    "               save_dir=folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_animated_history(dec.encoders_predictions_history[:],\n",
    "                      threeD=True,\n",
    "                      saving_name=folder_name+'/pretraining.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.compile(optimizer=SGD(0.01, 0.9), loss='kld')\n",
    "y_pred = dec.fit(x=unique_data, y=None, tol=0.01, maxiter=2e4, batch_size=2048,\n",
    "                 update_interval=200, save_dir=folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_animated_history(dec.encoders_clustering_history[:],threeD=True,saving_name=folder_name+'/clustering.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoded = dec.encoder.predict(unique_data)\n",
    "Clusters_p = dec.model.predict(unique_data)\n",
    "\n",
    "clrs = sns.color_palette(\"hls\", dec.n_clusters)\n",
    "fig, ax = plt.subplots(1,figsize=(15,15))\n",
    "for i in range(len(Encoded)):\n",
    "    idx = Clusters_p[i].argmax()\n",
    "    point = ax.scatter(Encoded[i,1], Encoded[i,0], s=2)\n",
    "    point.set_color(clrs[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = r'/home/alireza/Clustering/'\n",
    "labeled_accounts = pd.read_csv(loc+ \"/labeled_accounts.csv\",sep=';',encoding='cp437')[:805]\n",
    "unique_ones,b,counts = np.unique(labeled_accounts['TXT50'].values,return_inverse=True,return_counts=True)\n",
    "idx = np.where(counts!=1)[0]\n",
    "for acc in unique_ones[idx]:\n",
    "    idx2 = np.where(labeled_accounts['TXT50'].values==acc)[0]\n",
    "    labeled_accounts.loc[idx2[0],'TXT50'] = labeled_accounts.loc[idx2[0],'TXT50']+'_DUPLICATE'\n",
    "len(np.unique(labeled_accounts['TXT50'].values))\n",
    "Acc_frq_in_Dset = pd.DataFrame(np.sum(unique_data,axis=0), index=labeled_accounts['TXT50'].values.tolist(),\n",
    "                                                           columns=['In_dataset_frequency'])\n",
    "Acc_frq_in_Dset.index.name = 'Accounts_label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clusters_p = dec.model.predict(unique_data)\n",
    "clusters_list=[]\n",
    "for i in range(unique_data.shape[0]):\n",
    "    cluster_id = Clusters_p[i].argmax()\n",
    "    active_accounts = labeled_accounts.loc[np.where(unique_data[i]==1)[0]]['TXT50'].values\n",
    "    \n",
    "    clusters_list.append([cluster_id,\n",
    "                          active_accounts,\n",
    "                          len(active_accounts)])\n",
    "       \n",
    "clusters_df=pd.DataFrame(clusters_list,\n",
    "                         columns=['Cluster_id', 'Active_acounts_label','N_active_accounts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clusters_info= []\n",
    "for cluster_id in range(dec.n_clusters):\n",
    "    \n",
    "    Cluster = clusters_df.loc[clusters_df['Cluster_id']==cluster_id]\n",
    "    Cluster_size = len(Cluster)\n",
    "    cluster_acc = Cluster['Active_acounts_label'].values\n",
    "    \n",
    "    All_acc_in_clst = []\n",
    "    for i in range(len(cluster_acc)):\n",
    "        All_acc_in_clst += [acc for acc in cluster_acc[i]]\n",
    "    In_cluster_unique_accs, In_clst_frq = np.unique(All_acc_in_clst, return_counts=True)\n",
    "    In_Dset_frq = []\n",
    "    for account in In_cluster_unique_accs:\n",
    "        Dset_frq = Acc_frq_in_Dset.at[account,'In_dataset_frequency']\n",
    "        #print(account,type(Dset_frq))\n",
    "        In_Dset_frq.append(Dset_frq)\n",
    "    \n",
    "    accounts_info = np.asarray((In_cluster_unique_accs,\n",
    "                                In_clst_frq,\n",
    "                                In_Dset_frq,\n",
    "                                np.round(In_clst_frq/Cluster_size,decimals=1),\n",
    "                                np.round(In_clst_frq/In_Dset_frq, decimals=1),\n",
    "                                #np.round(In_clst_frq/len(All_acc_in_clst),decimals=2)\n",
    "                               )).T\n",
    "    Cluster_info_df = pd.DataFrame(accounts_info,\n",
    "                                   columns=['Unique_accounts',\n",
    "                                            'In_cluster_frequency',\n",
    "                                            'In_dataset_frequency',\n",
    "                                            'In_cluster_frequency/cluster_size',\n",
    "                                            'In_cluster_frequency/In_dataset_frequency',\n",
    "                                            #'In_cluster_frequency/len(All_accounts_in_cluster)'\n",
    "                                           ])\n",
    "    all_clusters_info.append([Cluster_info_df, Cluster_size])\n",
    "    \n",
    "all_Clusters_info_df = pd.DataFrame(all_clusters_info, columns=['Cluster_info_DataFrame','Cluster_size'])\n",
    "all_Clusters_info_df.index.name = 'Cluster_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_Clusters_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_Clusters_info_df.at[8,'Cluster_info_DataFrame'].sort_values(by=['In_cluster_frequency/cluster_size','In_cluster_frequency/In_dataset_frequency'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(all_Clusters_info_df,\n",
    "            open(folder_name+'/Clusters_df.p',\n",
    "                  \"wb\"),\n",
    "                  protocol=4)\n",
    "pickle.dump(dec,\n",
    "            open(folder_name+'/dec_model.p',\n",
    "                  \"wb\"),\n",
    "                  protocol=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
